{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The AND Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's parameter initialization\n",
    "W = [0.1,0.7]\n",
    "bias = 0.5\n",
    "learn_rate = 0.01\n",
    "\n",
    "# Training Set\n",
    "inputs = [[1,1],[-1,1],[1,-1],[-1,-1]]\n",
    "outputs = [1,-1,-1,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def and_perceptron():\n",
    "    global W\n",
    "    global bias\n",
    "    global learn_rate\n",
    "    global inputs\n",
    "    global outputs\n",
    "    error_nb = -1\n",
    "    while error_nb != 0:\n",
    "        print('\\x1b[1;34m'+'New Epoch:'+'\\x1b[0m')\n",
    "        error_nb = 0\n",
    "        example_nb = 0\n",
    "        while example_nb < len(inputs):\n",
    "            print(example_nb + 1, \"° training example: \", inputs[example_nb])\n",
    "\n",
    "            observation_nb = 0\n",
    "            integration_func = 0\n",
    "            while observation_nb < len(inputs[example_nb]):\n",
    "                integration_func += W[observation_nb] * inputs[example_nb][observation_nb]\n",
    "                observation_nb += 1\n",
    "\n",
    "            if integration_func >= bias:\n",
    "                predicted_output = 1\n",
    "            else:\n",
    "                predicted_output = -1\n",
    "\n",
    "            error = outputs[example_nb] - predicted_output\n",
    "            print('\\x1b[1;31m'+'Error='+'\\x1b[0m',error)\n",
    "    \n",
    "            if error != 0:\n",
    "                error_nb +=1\n",
    "                observation_nb = 0\n",
    "                while observation_nb < len(inputs[example_nb]):\n",
    "                    W[observation_nb] =  W[observation_nb] + learn_rate*error*inputs[example_nb][observation_nb]\n",
    "                    print(\"W \", observation_nb +1, \": \", W[observation_nb])\n",
    "                    observation_nb += 1\n",
    "                bias = bias + learn_rate*error\n",
    "            example_nb += 1\n",
    "    \n",
    "    print('\\x1b[4;31m'+'Training completed:'+'\\x1b[0m')\n",
    "    print(\"W: \", W, \"bias: \", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mNew Epoch:\u001b[0m\n",
      "1 ° training example:  [1, 1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "2 ° training example:  [-1, 1]\n",
      "\u001b[1;31mError=\u001b[0m -2\n",
      "W  1 :  0.12000000000000001\n",
      "W  2 :  0.6799999999999999\n",
      "3 ° training example:  [1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "4 ° training example:  [-1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "\u001b[1;34mNew Epoch:\u001b[0m\n",
      "1 ° training example:  [1, 1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "2 ° training example:  [-1, 1]\n",
      "\u001b[1;31mError=\u001b[0m -2\n",
      "W  1 :  0.14\n",
      "W  2 :  0.6599999999999999\n",
      "3 ° training example:  [1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "4 ° training example:  [-1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "\u001b[1;34mNew Epoch:\u001b[0m\n",
      "1 ° training example:  [1, 1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "2 ° training example:  [-1, 1]\n",
      "\u001b[1;31mError=\u001b[0m -2\n",
      "W  1 :  0.16\n",
      "W  2 :  0.6399999999999999\n",
      "3 ° training example:  [1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "4 ° training example:  [-1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "\u001b[1;34mNew Epoch:\u001b[0m\n",
      "1 ° training example:  [1, 1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "2 ° training example:  [-1, 1]\n",
      "\u001b[1;31mError=\u001b[0m -2\n",
      "W  1 :  0.18\n",
      "W  2 :  0.6199999999999999\n",
      "3 ° training example:  [1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "4 ° training example:  [-1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "\u001b[1;34mNew Epoch:\u001b[0m\n",
      "1 ° training example:  [1, 1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "2 ° training example:  [-1, 1]\n",
      "\u001b[1;31mError=\u001b[0m -2\n",
      "W  1 :  0.19999999999999998\n",
      "W  2 :  0.5999999999999999\n",
      "3 ° training example:  [1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "4 ° training example:  [-1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "\u001b[1;34mNew Epoch:\u001b[0m\n",
      "1 ° training example:  [1, 1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "2 ° training example:  [-1, 1]\n",
      "\u001b[1;31mError=\u001b[0m -2\n",
      "W  1 :  0.21999999999999997\n",
      "W  2 :  0.5799999999999998\n",
      "3 ° training example:  [1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "4 ° training example:  [-1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "\u001b[1;34mNew Epoch:\u001b[0m\n",
      "1 ° training example:  [1, 1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "2 ° training example:  [-1, 1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "3 ° training example:  [1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "4 ° training example:  [-1, -1]\n",
      "\u001b[1;31mError=\u001b[0m 0\n",
      "\u001b[4;31mTraining completed:\u001b[0m\n",
      "W:  [0.21999999999999997, 0.5799999999999998] bias:  0.3799999999999999\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "and_perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(example_nb):\n",
    "    global W\n",
    "    global bias\n",
    "    global inputs\n",
    "    observation_nb = 0\n",
    "    integration_func = 0\n",
    "    while observation_nb < len(inputs[example_nb]):\n",
    "        integration_func += (W[observation_nb] * inputs[example_nb][observation_nb])\n",
    "        observation_nb += 1\n",
    "    print(\"\\n\", example_nb + 1, \"° test example: \", inputs[example_nb])    \n",
    "    if integration_func >= bias:\n",
    "        print(\"Output is 1\")\n",
    "    else:\n",
    "        print (\"Output is -1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 ° test example:  [1, 1]\n",
      "Output is 1\n",
      "\n",
      " 2 ° test example:  [-1, 1]\n",
      "Output is -1\n",
      "\n",
      " 3 ° test example:  [1, -1]\n",
      "Output is -1\n",
      "\n",
      " 4 ° test example:  [-1, -1]\n",
      "Output is -1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inputs)):\n",
    "    test(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
